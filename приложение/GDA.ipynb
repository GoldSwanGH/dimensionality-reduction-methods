{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.stats import multivariate_normal"
   ],
   "execution_count":57,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"5jBObjzAb8hWZKjYx89UzC",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def fit(x_train, y_train):\n",
    "    m = y_train.shape[0] # Number of training example\n",
    "    #Reshapeing the training set\n",
    "    x_train = x_train.reshape(m, -1)\n",
    "    input_feature = x_train.shape[1] # Number of input feature. In our case it's 4\n",
    "    class_label = len(np.unique(y_train.reshape(-1))) # Number of class. In our case its 3.\n",
    "    \n",
    "    # Start everything with zero first.\n",
    "    # Mean for each class. Each row contains an individual class. And each of the class input is 4 dimenstional\n",
    "    mu = np.zeros((class_label, input_feature))\n",
    "    # Each row will conatain the covariance matrix of each class.\n",
    "    # The covariance matrix is a square symettric matrix.\n",
    "    # It indicates how each of the input feature varies with each other.\n",
    "    sigma = np.zeros((class_label, input_feature, input_feature))\n",
    "    # Prior probability of each class.\n",
    "    # Its the measure of knowing the likelihood of any class before seeing the input data.\n",
    "    phi = np.zeros(class_label)\n",
    "\n",
    "    for label in range(class_label):\n",
    "        # Seperate all the training data for a single class\n",
    "        indices = (y_train == label)\n",
    "        \n",
    "        phi[label] = float(np.sum(indices)) \/ m\n",
    "        mu[label] = np.mean(x_train[indices, :], axis=0)\n",
    "        # Instead of writting the equation we used numpy covariance function. \n",
    "        sigma[label] = np.cov(x_train[indices, :], rowvar=0)\n",
    "    \n",
    "    return phi, mu, sigma"
   ],
   "execution_count":58,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"mcmkgHrenaGepFeyZptRyo",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def predict(x_tests, phi, mu, sigma):\n",
    "    # flatten the training data\n",
    "    x_tests = x_tests.reshape(x_tests.shape[0], -1)\n",
    "    class_label = mu.shape[0] # Number of label we have in our case it's k = 3\n",
    "    scores = np.zeros((x_tests.shape[0], class_label))  # Initially we set the each class probability to zero.\n",
    "    for label in range(class_label): # We will calculate the probability for each of the class.\n",
    "        # normal_distribution_prob.logpdf Will give us the log value of the PDF that we just mentioned above.\n",
    "        normal_distribution_prob = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "        # x_test can have multiple test data we will calculate the probability of each of the test data\n",
    "        for i, x_test in enumerate(x_tests):\n",
    "            scores[i, label] = np.log(phi[label]) + normal_distribution_prob.logpdf(x_test)\n",
    "    predictions = np.argmax(scores, axis=1)\n",
    "    return predictions"
   ],
   "execution_count":59,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"bI9ch5Sv2aJ9sAQwFMFwNj",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "phi, mu, sigma = fit(x_train, y_train)\n",
    "y_predict = predict(x_test, phi, mu, sigma)\n",
    "score = f1_score(y_test, y_predict, average=\"weighted\")\n",
    "print(\"f1 score of our model: \", score)\n",
    "\n",
    "# Compare this model with scikitlearn LinearDiscriminatorAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "y_predict_sk = lda.predict(x_test)\n",
    "print(\"f1 score of scikit-learn model is: \", f1_score(y_test, y_predict_sk, average=\"weighted\"))"
   ],
   "execution_count":60,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "f1 score of our model:  0.9740594802514307\n",
      "f1 score of scikit-learn model is:  0.9740594802514307\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Vlg4TfVrsHmYjd0iJFhylx",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}