{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import warnings\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import eye\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Kfda(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    \"\"\"Kernel Fisher Discriminant Analysis classifier.\n",
    "\n",
    "    Each class is represented by a centroid using projections in a\n",
    "    Hilbert space.\n",
    "\n",
    "    See https:\/\/arxiv.org\/abs\/1906.09436 for mathematical details.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_components : int the amount of Fisher directions to use.\n",
    "        This is limited by the amount of classes minus one.\n",
    "        See the paper for further discussion of this limit.\n",
    "\n",
    "    kernel : str, ['linear', 'poly', 'sigmoid', 'rbf','laplacian', 'chi2']\n",
    "        The kernel to use.\n",
    "        Use **kwds to pass arguments to these functions.\n",
    "        See\n",
    "        https:\/\/scikit-learn.org\/stable\/modules\/metrics.html#polynomial-kernel\n",
    "        for more details.\n",
    "\n",
    "    robustness_offset : float\n",
    "        The small value to add along the diagonal of N to gurantee\n",
    "        valid fisher directions.\n",
    "        Set this to 0 to disable the feature. Default: 1e-8.\n",
    "\n",
    "    **kwds : parameters to pass to the kernel function.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    centroids_ : array_like of shape (n_classes, n_samples) that\n",
    "        represent the class centroids.\n",
    "\n",
    "    classes_ : array of shape (n_classes,)\n",
    "        The unique class labels\n",
    "\n",
    "    weights_ : array of shape (n_components, n_samples) that\n",
    "        represent the fisher components.\n",
    "\n",
    "    clf_ : The internal NearestCentroid classifier used in prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components=2, kernel='linear', robustness_offset=1e-8,\n",
    "                 **kwds):\n",
    "        self.kernel = kernel\n",
    "        self.n_components = n_components\n",
    "        self.kwds = kwds\n",
    "        self.robustness_offset = robustness_offset\n",
    "\n",
    "        if kernel is None:\n",
    "            self.kernel = 'linear'\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the NearestCentroid model according to the given training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Training vector, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values (integers)\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        if self.n_components > self.classes_.size - 1:\n",
    "            warnings.warn(\n",
    "                \"n_components > classes_.size - 1.\"\n",
    "                \"Only the first classes_.size - 1 components will be valid.\"\n",
    "            )\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        y_onehot = OneHotEncoder().fit_transform(\n",
    "            self.y_[:, np.newaxis])\n",
    "\n",
    "        K = pairwise_kernels(\n",
    "            X, X, metric=self.kernel, **self.kwds)\n",
    "\n",
    "        m_classes = y_onehot.T @ K \/ y_onehot.T.sum(1)\n",
    "        indices = (y_onehot @ np.arange(self.classes_.size)).astype('i')\n",
    "        N = K @ (K - m_classes[indices])\n",
    "\n",
    "        # Add value to diagonal for rank robustness\n",
    "        N += eye(self.y_.size) * self.robustness_offset\n",
    "\n",
    "        m_classes_centered = m_classes - K.mean(1)\n",
    "        M = m_classes_centered.T @ m_classes_centered\n",
    "\n",
    "        # Find weights\n",
    "        w, self.weights_ = eigsh(M, self.n_components, N, which='LM')\n",
    "\n",
    "        # Compute centers\n",
    "        centroids_ = m_classes @ self.weights_\n",
    "\n",
    "        # Train nearest centroid classifier\n",
    "        self.clf_ = NearestCentroid().fit(centroids_, self.classes_)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Project the points in X onto the fisher directions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like} of shape (n_samples, n_features) to be\n",
    "            projected onto the fisher directions.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        return pairwise_kernels(\n",
    "            X, self.X_, metric=self.kernel, **self.kwds\n",
    "        ) @ self.weights_\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Perform classification on an array of test vectors X.\n",
    "\n",
    "        The predicted class C for each sample in X is returned.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : ndarray of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        X = check_array(X)\n",
    "\n",
    "        projected_points = self.transform(X)\n",
    "        predictions = self.clf_.predict(projected_points)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def fit_additional(self, X, y):\n",
    "        \"\"\"Fit new classes without recomputing weights.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_new_samples, n_nfeatures)\n",
    "        y : array, shape = [n_samples]\n",
    "            Target values (integers)\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        new_classes = np.unique(y)\n",
    "\n",
    "        projections = self.transform(X)\n",
    "        y_onehot = OneHotEncoder().fit_transform(\n",
    "            y[:, np.newaxis])\n",
    "        new_centroids = y_onehot.T @ projections \/ y_onehot.T.sum(1)\n",
    "\n",
    "        concatenated_classes = np.concatenate([self.classes_, new_classes])\n",
    "        concatenated_centroids = np.concatenate(\n",
    "            [self.clf_.centroids_, new_centroids])\n",
    "\n",
    "        self.clf_.fit(concatenated_centroids, concatenated_classes)\n",
    "\n",
    "        return self"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"HaWwcr1rdeKPRaj9NMr3Ct",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = (X - 127.5) \/ 127.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=1000, stratify=y)"
   ],
   "execution_count":2,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/datasets\/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"4kFXLfYsOiPItoAsh8jrMG",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "test_indices = random.sample(range(X_test.shape[0]), 16)\n",
    "test_sample = X_test[test_indices]\n",
    "test_sample_labels = y_test[test_indices]\n",
    "\n",
    "f, axs = plt.subplots(4, 4)\n",
    "flattened_axs = itertools.chain(*axs)\n",
    "\n",
    "for ax, img, label in zip(flattened_axs, test_sample, test_sample_labels):\n",
    "  ax.axis('off')\n",
    "  ax.imshow(img.reshape(28,28))\n",
    "  ax.set_title(f'Label: {label}')\n",
    "\n",
    "plt.tight_layout()"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"gLKebwkC9cRUWxpUijB1Dc",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "cls = Kfda(kernel='rbf', n_components=9)\n",
    "cls.fit(X_train, y_train)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"K4dwiOTTZiVWZsrA373rjH",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "print('Scores:')\n",
    "test_score = cls.score(X_test, y_test)\n",
    "print(f'Test Score: {test_score}')\n",
    "train_score = cls.score(X_train, y_train)\n",
    "print(f'Train Score: {train_score}')"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"UJnCY3P2bMSDR5MHZC1FXZ",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "predictions = cls.predict(test_sample)\n",
    "\n",
    "f, axs = plt.subplots(4, 4)\n",
    "\n",
    "flattened_axs = itertools.chain(*axs)\n",
    "\n",
    "for ax, img, prediction in zip(flattened_axs, test_sample, predictions):\n",
    "  (ax.axis('off'))\n",
    "  ax.imshow(img.reshape(28,28))\n",
    "  ax.set_title(f'Prediction: {prediction}')\n",
    "plt.tight_layout()"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"g0220QxWB3xGWTjKtrmD1H",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Чтобы получить более общее представление об ошибках, посмотрите на матрицу путаницы.\n",
    "Более высокая интенсивность означает, что по оси X прогнозируется больше значений по оси Y.\n",
    "Эта матрица путаницы показывает, что почти все прогнозы верны, без очевидной распространенной ошибки."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"kRdJUtOt5TCxnrYvmsorjm",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = cls.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "pos = plt.imshow(confusion)\n",
    "plt.colorbar(pos)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"5hlPsqcax3FGG0bKnK2ty2",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}